spring.ai.ollama.base-url=${OLLAMA-BASE-URL:http://localhost:11434}
document-token-limit=9000
embedding-token-limit=500
spring.liquibase.change-log=classpath:/dbchangelog/db.changelog-master-ollama.xml

# sql creation
# sql model for free production use with clause that fine tuned values have to be published.
#spring.ai.ollama.chat.model=sqlcoder:70b-alpha-q6_K

# document processing
# config free production use
# best model for documents currently
#spring.ai.ollama.chat.options.model=qwen2.5:32b
#spring.ai.ollama.chat.options.model=deepseek-r1:14b
#spring.ai.ollama.chat.options.model=llama3.1:8b
#spring.ai.ollama.chat.options.num-ctx=12288
spring.ai.embedding.transformer.onnx.modelUri=https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1/resolve/main/onnx/model_quantized.onnx
spring.ai.embedding.transformer.tokenizer.uri=https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1/resolve/main/tokenizer.json

# function calling
# best model for function calls currently
#spring.ai.ollama.chat.options.model=qwen2.5:14b
#spring.ai.ollama.chat.options.num-ctx=40960

#spring.ai.ollama.chat.model=llama3.1:8b
#spring.ai.ollama.chat.options.model=llama3.1:8b
#spring.ai.ollama.chat.options.num-ctx=65535

# image processing
# best model for vision currently
#spring.ai.ollama.chat.options.model=llama3.2-vision
#spring.ai.ollama.chat.options.num-thread=8
#spring.ai.ollama.chat.options.keep_alive=1s

#spring.ai.ollama.chat.options.model=llava:34b-v1.6-q6_K


# generate code
# best model for code generation currently
#spring.ai.ollama.chat.options.model=ollama run devstral:24b
#spring.ai.ollama.chat.options.model=codestral:22b
#spring.ai.ollama.chat.options.num-ctx=32768

#spring.ai.ollama.chat.options.model=granite-code:20b
#spring.ai.ollama.chat.options.num-ctx=8192

#spring.ai.ollama.chat.options.num-thread=8
#spring.ai.ollama.chat.options.keep_alive=1s

#spring.ai.ollama.chat.options.model=deepseek-coder-v2:16b
#spring.ai.ollama.chat.options.num-ctx=65536

# generate book summaries
# best model for book summaries currently
#spring.ai.ollama.chat.options.model=qwen2.5:32b
#spring.ai.ollama.chat.options.num-ctx=30720
spring.ai.ollama.chat.options.num-thread=8
spring.ai.ollama.chat.options.keep_alive=1s

# mcp-server
spring.ai.ollama.chat.options.model=qwen3:32b
spring.ai.ollama.chat.options.num-ctx=32768

#spring.ai.ollama.chat.options.model=llama3.1:70b
#spring.ai.ollama.chat.options.num-ctx=131072

#spring.ai.ollama.chat.options.num-ctx=32768
