spring.ai.ollama.base-url=${OLLAMA-BASE-URL:http://localhost:11434}
spring.ai.ollama.embedding.enabled=false
spring.ai.embedding.transformer.enabled=true
document-token-limit=9000
embedding-token-limit=500
spring.liquibase.change-log=classpath:/dbchangelog/db.changelog-master-ollama.xml

# sql creation
# sql model for free production use with clause that fine tuned values have to be published.
#spring.ai.ollama.chat.model=sqlcoder:70b-alpha-q6_K

# document processing
# config free production use
#spring.ai.ollama.chat.model=qwen2.5:32b
spring.ai.ollama.chat.model=llama3.1:8b
spring.ai.ollama.chat.options.num-ctx=12288
#spring.ai.embedding.transformer.onnx.modelUri=https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1/tree/main/onnx/model_quantized.onnx
#spring.ai.embedding.transformer.tokenizer.uri=https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1/tree/main/tokenizer.json

# function calling
#spring.ai.ollama.chat.model=llama3.1:8b
#spring.ai.ollama.chat.options.num-ctx=65535

# image processing
#spring.ai.ollama.chat.model=llava:34b-v1.6-q6_K
#spring.ai.ollama.chat.options.num-thread=8
#spring.ai.ollama.chat.options.keep_alive=1s

# generate code
#spring.ai.ollama.chat.model=granite-code:20b
#spring.ai.ollama.chat.options.num-ctx=8192

#spring.ai.ollama.chat.options.num-thread=8
#spring.ai.ollama.chat.options.keep_alive=1s

#spring.ai.ollama.chat.model=deepseek-coder-v2:16b
#spring.ai.ollama.chat.options.num-ctx=65536

#spring.ai.ollama.chat.model=codestral:22b
#spring.ai.ollama.chat.options.num-ctx=32768

# generate book summaries
spring.ai.ollama.chat.options.num-thread=8
spring.ai.ollama.chat.options.keep_alive=1s

#spring.ai.ollama.chat.model=llama3.1:70b
#spring.ai.ollama.chat.options.num-ctx=131072
#spring.ai.ollama.chat.model=qwen2.5:32b
#spring.ai.ollama.chat.options.num-ctx=32768
#spring.ai.ollama.chat.options.num-ctx=30720
